# coding:utf-8

'''
__name__ ='data_preprocessing'
__Audthor__ = 'zzds'
__version__ ='0.1.0'
'''
import numpy as np
import pandas as pd
import os, sys
from datetime import datetime, timedelta
import copy

os.chdir(os.path.dirname(sys.argv[0]))
sys.path.append(os.getcwd())

#导入数据
borrow_train = pd.read_csv(r'.\data\train\borrow_train.txt',header=None,names=['stu_id','borrow_date','book_name','book_type'],parse_dates = ['borrow_date'])
card_train = pd.read_csv(r'.\data\train\card_train.txt',header=None,names=['stu_id','cost_type','cost_pos','cost_reason','cost_time','cost_amount','rest_amount'])
library_train = pd.read_csv(r'.\data\train\library_train.txt',header=None,names=['stu_id','gate','time'],parse_dates = ['time'])
score_train = pd.read_csv(r'.\data\train\score_train.txt',header=None,names=['stu_id','department_id','rank'])
subsidy_train = pd.read_csv(r'.\data\train\subsidy_train.txt',header=None,names=['stu_id','subsidy'])
#去重
library_train.drop_duplicates(inplace = True)
card_train.drop_duplicates(inplace = True)

sub_1000_train = subsidy_train[subsidy_train.subsidy == 1000].merge(score_train,on = 'stu_id')
sub_1500_train = subsidy_train[subsidy_train.subsidy == 1500].merge(score_train,on = 'stu_id')
sub_2000_train = subsidy_train[subsidy_train.subsidy == 2000].merge(score_train,on = 'stu_id')

data_train = subsidy_train.merge(score_train,on = 'stu_id')
data_train = data_train.merge(library_train,on = 'stu_id')

score_train.groupby('department_id')['stu_id'].count()

card_train = card_train.merge(subsidy_train,on = 'stu_id')

groupedborrow = borrow_train.groupby('stu_id',as_index = False)[['book_name']].count()
groupedlibrary = library_train.groupby('stu_id',as_index = False)[['time']].count()
groupedsubsidy = card_train.groupby(['subsidy','stu_id'],as_index = False)[['cost_amount']].sum()
data = groupedsubsidy.merge(groupedlibrary,on = 'stu_id',how = 'left').fillna(0)
data = data.merge(groupedborrow,on = 'stu_id',how = 'left').fillna(0)
data.set_index(['subsidy','stu_id'])
